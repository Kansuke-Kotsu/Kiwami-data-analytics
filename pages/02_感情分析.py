import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, spearmanr
import re
import io

# MeCabä¸è¦ã®ç°¡æ˜“æ„Ÿæƒ…åˆ†æã‚¯ãƒ©ã‚¹
class SimpleSentimentAnalyzer:
    """MeCabã«ä¾å­˜ã—ãªã„ç°¡æ˜“æ„Ÿæƒ…åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        # åŸºæœ¬çš„ãªæ„Ÿæƒ…èªå½™è¾æ›¸ï¼ˆæ—¥æœ¬èªï¼‰
        self.positive_words = {
            'å¬‰ã—ã„': 0.8, 'ã†ã‚Œã—ã„': 0.8, 'æ¥½ã—ã„': 0.7, 'ãŸã®ã—ã„': 0.7,
            'è‰¯ã„': 0.6, 'ã‚ˆã„': 0.6, 'ã„ã„': 0.6, 'ã™ã”ã„': 0.7, 'ã™ã°ã‚‰ã—ã„': 0.9,
            'ã™ã¦ã': 0.7, 'ç´ æ•µ': 0.7, 'æœ€é«˜': 0.9, 'ç´ æ™´ã‚‰ã—ã„': 0.9, 'æ„Ÿå‹•': 0.8,
            'æ„›': 0.8, 'å¥½ã': 0.7, 'å¹¸ã›': 0.8, 'æˆåŠŸ': 0.7, 'å‹åˆ©': 0.8,
            'ã‚ã‚ŠãŒã¨ã†': 0.7, 'ãŒã‚“ã°ã‚‹': 0.6, 'é ‘å¼µã‚‹': 0.6, 'ç¬‘é¡”': 0.7, 'ãŠã‚ã§ã¨ã†': 0.8,
            'é¢ç™½ã„': 0.6, 'ãŠã‚‚ã—ã‚ã„': 0.6, 'ã‹ã‚ã„ã„': 0.6, 'ãã‚Œã„': 0.6, 'ç¾ã—ã„': 0.7,
            'å®‰å¿ƒ': 0.6, 'æº€è¶³': 0.7, 'å……å®Ÿ': 0.7, 'å¿«é©': 0.6, 'å¹³å’Œ': 0.6
        }
        
        self.negative_words = {
            'æ‚²ã—ã„': -0.8, 'ã‹ãªã—ã„': -0.8, 'è¾›ã„': -0.7, 'ã¤ã‚‰ã„': -0.7,
            'æ‚ªã„': -0.6, 'ã‚ã‚‹ã„': -0.6, 'ã ã‚': -0.6, 'ãƒ€ãƒ¡': -0.6, 'æœ€æ‚ª': -0.9,
            'å«Œã„': -0.7, 'ãã‚‰ã„': -0.7, 'å«Œ': -0.6, 'æ€’ã‚Š': -0.8, 'è…¹ç«‹ã¤': -0.7,
            'å¤±æ•—': -0.7, 'å›°ã‚‹': -0.6, 'ä¸å®‰': -0.7, 'å¿ƒé…': -0.6, 'ç–²ã‚Œã‚‹': -0.5,
            'ç—…æ°—': -0.6, 'ç—›ã„': -0.6, 'ã¤ã¾ã‚‰ãªã„': -0.6, 'é€€å±ˆ': -0.5, 'é¢å€’': -0.5,
            'å±é™º': -0.7, 'å•é¡Œ': -0.6, 'å›°é›£': -0.7, 'è‹¦ã—ã„': -0.8, 'ã‚€ã‹ã¤ã': -0.7,
            'çµ¶æœ›': -0.9, 'ã‚¹ãƒˆãƒ¬ã‚¹': -0.6, 'ä¸æº€': -0.6, 'å¾Œæ‚”': -0.7, 'ææ€–': -0.8
        }
        
        # å¼·èª¿èªã®é‡ã¿èª¿æ•´
        self.intensifiers = {
            'ã¨ã¦ã‚‚': 1.5, 'ã™ã”ã': 1.4, 'æœ¬å½“ã«': 1.3, 'ã‚ã¡ã‚ƒãã¡ã‚ƒ': 1.6,
            'ã‹ãªã‚Š': 1.3, 'ã‚‚ã®ã™ã”ã': 1.5, 'éå¸¸ã«': 1.4, 'è¶…': 1.4,
            'å°‘ã—': 0.7, 'ã¡ã‚‡ã£ã¨': 0.6, 'ã‚„ã‚„': 0.8, 'è‹¥å¹²': 0.7
        }
        
        # å¦å®šèª
        self.negators = ['ãªã„', 'ãš', 'ã¬', 'ã§ã‚‚', 'ã‘ã©', 'ãŒ']
    
    def analyze(self, text):
        """ç°¡æ˜“æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œ"""
        if not text or not isinstance(text, str):
            return 0.0
        
        text = text.lower().strip()
        words = re.findall(r'[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠæ¼¢å­—ä¸€-é¾¯]+', text)
        
        score = 0.0
        word_count = 0
        
        for i, word in enumerate(words):
            # ãƒã‚¸ãƒ†ã‚£ãƒ–èªå½™ã®ãƒã‚§ãƒƒã‚¯
            if word in self.positive_words:
                word_score = self.positive_words[word]
                word_count += 1
                
            # ãƒã‚¬ãƒ†ã‚£ãƒ–èªå½™ã®ãƒã‚§ãƒƒã‚¯  
            elif word in self.negative_words:
                word_score = self.negative_words[word]
                word_count += 1
            else:
                continue
            
            # å¼·èª¿èªã®èª¿æ•´
            if i > 0 and words[i-1] in self.intensifiers:
                word_score *= self.intensifiers[words[i-1]]
            
            # å¦å®šèªã®èª¿æ•´ï¼ˆç°¡æ˜“ï¼‰
            negation_context = ' '.join(words[max(0, i-2):i])
            for neg in self.negators:
                if neg in negation_context:
                    word_score *= -0.8
                    break
            
            score += word_score
        
        # æ­£è¦åŒ–ï¼ˆ-1ã‹ã‚‰1ã®ç¯„å›²ã«èª¿æ•´ï¼‰
        if word_count == 0:
            return 0.0
        
        normalized_score = score / word_count
        return max(-1.0, min(1.0, normalized_score))

st.set_page_config(page_title="â‘¡ æ„Ÿæƒ…åˆ†æ ", page_icon="", layout="wide")
st.title("æ„Ÿæƒ…åˆ†æã«ã‚ˆã‚‹åç›Šç›¸é–¢åˆ†æ")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
if "df" not in st.session_state:
    st.warning("ã¾ãšãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã§Excelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

df = st.session_state["df"].copy()
meta = st.session_state.get("meta", {})

# æ„Ÿæƒ…åˆ†æå™¨ã®åˆæœŸåŒ–
analyzer = None
use_simple_mode = st.session_state.get("use_simple_sentiment", False)

# ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ã§ã®å¼·åˆ¶å®Ÿè¡Œãƒã‚§ãƒƒã‚¯
if "force_simple_mode" in st.query_params:
    use_simple_mode = True
    st.session_state.use_simple_sentiment = True

if use_simple_mode:
    # ç°¡æ˜“æ„Ÿæƒ…åˆ†æãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨
    analyzer = SimpleSentimentAnalyzer()
    st.info("ğŸš€ ç°¡æ˜“æ„Ÿæƒ…åˆ†æãƒ¢ãƒ¼ãƒ‰ (MeCabä¸è¦) ã§å‹•ä½œä¸­")
else:
    # oseti ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç¢ºèªã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    try:
        import oseti
        
        # MeCabè¨­å®šã‚¨ãƒ©ãƒ¼ã®å …ç‰¢ãªãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        def initialize_oseti_analyzer():
            """ã‚ˆã‚Šå …ç‰¢ãªoseti AnalyzeråˆæœŸåŒ–"""
            
            # Streamlitç’°å¢ƒç”¨ã®æ‹¡å¼µMeCabè¨­å®šãƒªã‚¹ãƒˆ
            mecab_configs = [
                # æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªè¨­å®šã‹ã‚‰è©¦è¡Œ
                "-r ''",                    # ç©ºã®rcè¨­å®š
                "-r /dev/null",             # rcç„¡åŠ¹åŒ–
                "",                         # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
                "-Owakati",                 # åˆ†ã‹ã¡æ›¸ããƒ¢ãƒ¼ãƒ‰
                "-r /etc/mecabrc",          # ä¸€èˆ¬çš„ãªLinuxè¨­å®š
                "-r /usr/local/etc/mecabrc",# macOS Homebrewè¨­å®š
                "-d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd",  # Ubuntuè¾æ›¸
                "-d /usr/local/lib/mecab/dic/ipadic",  # macOSæ¨™æº–è¾æ›¸
                "-d /usr/share/mecab/dic/ipadic",      # Debian/Ubuntuæ¨™æº–
                "-F%m ",                    # æœ€å°å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            ]
            
            # é€²æ—è¡¨ç¤º
            progress_placeholder = st.empty()
            progress_placeholder.info("ğŸ”§ MeCabè¨­å®šã‚’è‡ªå‹•èª¿æ•´ä¸­...")
            
            for i, config in enumerate(mecab_configs):
                try:
                    progress_placeholder.info(f"ğŸ”§ MeCabè¨­å®šã‚’è©¦è¡Œä¸­... ({i+1}/{len(mecab_configs)}) {config or 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ'}")
                    
                    if config == "":
                        test_analyzer = oseti.Analyzer()
                    else:
                        test_analyzer = oseti.Analyzer(mecab_args=config)
                    
                    # ç°¡å˜ãªå‹•ä½œãƒ†ã‚¹ãƒˆ
                    test_result = test_analyzer.analyze("ãƒ†ã‚¹ãƒˆ")
                    if test_result is not None:
                        progress_placeholder.success(f"âœ… MeCabè¨­å®šãŒæ­£å¸¸ã«æ§‹æˆã•ã‚Œã¾ã—ãŸï¼ (è¨­å®š: {config or 'ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ'})")
                        return test_analyzer
                        
                except Exception as e:
                    # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’è©³ç´°ã«è¨˜éŒ²ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
                    if st.secrets.get("debug_mode", False):
                        st.write(f"è¨­å®š `{config}` ã§ã‚¨ãƒ©ãƒ¼: {str(e)}")
                    continue
            
            # å…¨ã¦ã®è¨­å®šãŒå¤±æ•—ã—ãŸå ´åˆ
            progress_placeholder.empty()
            return None
    
    # MeCabåˆæœŸåŒ–å®Ÿè¡Œ
    try:
        analyzer = initialize_oseti_analyzer()
        
        if analyzer is None:
            # å…¨ã¦å¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            st.error("ğŸš¨ MeCabã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            # Streamlitç’°å¢ƒã«ç‰¹åŒ–ã—ãŸã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³
            st.markdown("""
            ### ğŸ’¡ Streamlitç’°å¢ƒã§ã®è§£æ±ºæ–¹æ³•
            
            #### **æ–¹æ³•1: ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ç¢ºèª**
            """)
            
            st.code("""
# 1. MeCabã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç¢ºèª
# macOS (Homebrew):
brew list mecab mecab-ipadic || brew install mecab mecab-ipadic

# Ubuntu/Debian:
apt list --installed | grep mecab || sudo apt-get install mecab mecab-ipadic-utf8

# CentOS/RHEL:
yum list installed | grep mecab || sudo yum install mecab mecab-ipadic
            """)
            
            st.markdown("#### **æ–¹æ³•2: Pythonç’°å¢ƒã®ãƒªã‚»ãƒƒãƒˆ**")
            st.code("""
# 2. Python MeCabãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ã®å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip uninstall -y mecab-python3 oseti
pip install --no-cache-dir mecab-python3==1.0.6
pip install --no-cache-dir oseti==0.2.0
            """)
            
            st.markdown("#### **æ–¹æ³•3: ç’°å¢ƒå¤‰æ•°ã®è¨­å®š**")
            st.code("""
# 3. ç’°å¢ƒå¤‰æ•°ã§MeCabè¾æ›¸ãƒ‘ã‚¹ã‚’æ˜ç¤º
export MECAB_DICDIR=/usr/local/lib/mecab/dic/ipadic  # macOS
export MECAB_DICDIR=/usr/lib/mecab/dic/ipadic        # Linux
            """)
            
            st.markdown("#### **æ–¹æ³•4: Dockerç’°å¢ƒã®å ´åˆ**")
            st.code("""
# Dockerfile ã«è¿½åŠ 
RUN apt-get update && apt-get install -y mecab mecab-ipadic-utf8 libmecab-dev
ENV MECAB_DICDIR /usr/lib/mecab/dic/ipadic
            """)
            
            # ä»£æ›¿æ¡ˆã®æç¤º
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ğŸš€ ç°¡æ˜“æ„Ÿæƒ…åˆ†æãƒ¢ãƒ¼ãƒ‰ã§ç¶šè¡Œ", type="primary"):
                    st.session_state.use_simple_sentiment = True
                    st.rerun()
                st.info("MeCabä¸è¦ã®åŸºæœ¬çš„ãªæ„Ÿæƒ…åˆ†æã§ç¶šè¡Œã—ã¾ã™")
            
            with col2:
                st.info("ğŸ“ **æ¨å¥¨**: ä¸Šè¨˜ã®è§£æ±ºæ–¹æ³•ã‚’è©¦ã™ã‹ã€LLMç‰ˆã‚’ã”åˆ©ç”¨ãã ã•ã„")
                if st.button("ğŸ”„ MeCabã®è¨­å®šã‚’å†è©¦è¡Œ"):
                    st.rerun()
            
            st.stop()
            
        except Exception as e:
            st.error(f"åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")
            st.info("ğŸ“ ã“ã®ã‚¨ãƒ©ãƒ¼ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦é–‹ç™ºè€…ã«å ±å‘Šã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        
    except ImportError:
        st.error("osetiãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.code("pip install oseti==0.2.0")
        st.info("requirements.txtã«osetiã‚’è¿½åŠ ã—ã¦å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚")
        st.stop()
    except Exception as e:
        st.error(f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.info("æŠ€è¡“çš„ãªå•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")
        st.stop()

# ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ãŒæ­£å¸¸ã«åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
if analyzer is None:
    st.error("æ„Ÿæƒ…åˆ†æå™¨ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    st.stop()

# åˆ—é¸æŠ
st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿åˆ—é¸æŠ")
col1, col2 = st.columns(2)

with col1:
    script_col = st.selectbox(
        "å°æœ¬ãƒ‡ãƒ¼ã‚¿åˆ—",
        options=list(df.columns),
        index=list(df.columns).index(meta.get("text_col")) if meta.get("text_col") in df.columns else 0
    )

with col2:
    revenue_options = [c for c in df.columns if c != script_col]
    default_idx = revenue_options.index(meta.get("profit_col")) if meta.get("profit_col") in revenue_options else 0
    revenue_col = st.selectbox(
        "åç›Šãƒ‡ãƒ¼ã‚¿åˆ—",
        options=revenue_options,
        index=default_idx
    )


# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
df_clean = df.copy()
df_clean[script_col] = df_clean[script_col].fillna("").astype(str)
df_clean[revenue_col] = pd.to_numeric(df_clean[revenue_col], errors="coerce")

# æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
valid_data = df_clean[
    (df_clean[script_col].str.strip() != "") & 
    (df_clean[revenue_col].notna())
].copy()

if len(valid_data) == 0:
    st.error("æœ‰åŠ¹ãªå°æœ¬ãƒ‡ãƒ¼ã‚¿ã¨åç›Šãƒ‡ãƒ¼ã‚¿ã®ãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    st.stop()

st.info(f"ğŸ“Š æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(valid_data):,}ä»¶ / å…¨ä½“: {len(df):,}ä»¶")

# åˆ†æè¨­å®š
st.subheader("âš™ï¸ æ„Ÿæƒ…åˆ†æè¨­å®š")

col1, col2 = st.columns(2)
with col1:
    max_samples = st.slider(
        "æœ€å¤§åˆ†æä»¶æ•°ï¼ˆå‡¦ç†é€Ÿåº¦èª¿æ•´ï¼‰",
        min_value=10,
        max_value=min(2000, len(valid_data)),
        value=min(500, len(valid_data)),
        step=50
    )

with col2:
    text_preprocessing = st.selectbox(
        "ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†",
        ["åŸºæœ¬å‰å‡¦ç†", "è©³ç´°å‰å‡¦ç†"]
    )

# ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
if len(valid_data) > max_samples:
    sample_data = valid_data.sample(n=max_samples, random_state=42)
    st.info(f"ğŸ¯ {max_samples}ä»¶ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¾ã—ãŸ")
else:
    sample_data = valid_data
    st.info(f"ğŸ“‹ å…¨{len(sample_data)}ä»¶ã‚’åˆ†æã—ã¾ã™")

# ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†é–¢æ•°
def preprocess_text(text, mode="basic"):
    """ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†"""
    if mode == "è©³ç´°å‰å‡¦ç†":
        # URLã€ãƒ¡ãƒ¼ãƒ«ã€æ•°å­—ã‚’é™¤å»
        text = re.sub(r'https?://[\w/:%#\$&\?\(\)~\.=\+\-]+', '', text)
        text = re.sub(r'[\w\.-]+@[\w\.-]+\.\w+', '', text)
        text = re.sub(r'\d+', '', text)
        # è¨˜å·ã®ä¸€éƒ¨ã‚’é™¤å»
        text = re.sub(r'[ã€ã€‘ã€Œã€ã€ã€ï¼ˆï¼‰()[\]{}]', '', text)
        # æ”¹è¡Œã¨ã‚¿ãƒ–ã‚’ç©ºç™½ã«
        text = re.sub(r'[\r\n\t]+', ' ', text)
        # é€£ç¶šã™ã‚‹ç©ºç™½ã‚’1ã¤ã«
        text = re.sub(r'\s+', ' ', text)
    
    return text.strip()

# æ„Ÿæƒ…åˆ†æé–¢æ•°
def analyze_sentiment_batch(texts, preprocessing_mode="basic"):
    """ãƒãƒƒãƒæ„Ÿæƒ…åˆ†æï¼ˆoseti ã¾ãŸã¯ ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰"""
    results = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, text in enumerate(texts):
        try:
            # ãƒ†ã‚­ã‚¹ãƒˆå‰å‡¦ç†
            processed_text = preprocess_text(text, preprocessing_mode)
            
            if len(processed_text.strip()) == 0:
                # ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã®å ´åˆã¯ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã‚¹ã‚³ã‚¢
                sentiment_scores = {
                    "positive": 0.0,
                    "negative": 0.0, 
                    "neutral": 1.0,
                    "compound": 0.0
                }
            else:
                # æ„Ÿæƒ…åˆ†æå™¨ã®ã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†å²
                if isinstance(analyzer, SimpleSentimentAnalyzer):
                    # ç°¡æ˜“æ„Ÿæƒ…åˆ†æã®å ´åˆ
                    compound_score = analyzer.analyze(processed_text)
                else:
                    # oseti ã«ã‚ˆã‚‹æ„Ÿæƒ…åˆ†æã®å ´åˆ
                    scores = analyzer.analyze(processed_text)
                    # scores ã¯ listï¼ˆå„æ–‡ã®ã‚¹ã‚³ã‚¢ï¼‰ãªã®ã§ã€å…¨ä½“ã®è¤‡åˆã‚¹ã‚³ã‚¢ã‚’å¹³å‡ã§é›†ç´„
                    if isinstance(scores, (list, tuple, np.ndarray)):
                        if len(scores) == 0:
                            compound_score = 0.0
                        else:
                            compound_score = float(np.mean(scores))
                    else:
                        # ç¨€ã«å˜ä¸€æ•°å€¤ãŒè¿”ã£ã¦ãã¦ã‚‚å®‰å…¨ã«å‡¦ç†
                        compound_score = float(scores)

                # compound_score ã¯ -1ã€œ1 ã‚’å–ã‚Šã†ã‚‹æƒ³å®š
                # ã‚·ãƒ³ãƒ—ãƒ«ã«ã€Œæ­£ï¼è² ï¼ä¸­ç«‹ã€ã‚’å‰²ã‚Šå½“ã¦ï¼ˆåˆè¨ˆãŒ1ã«ãªã‚‹ã‚ˆã†ã«ï¼‰
                if compound_score > 0.1:
                    positive = abs(compound_score)     # æ­£ã®å€¤ã‚’æ­£è¦åŒ–
                    negative = 0.0
                    neutral  = 1.0 - positive
                elif compound_score < -0.1:
                    positive = 0.0
                    negative = abs(compound_score)     # è² ã®å€¤ã‚’æ­£ã®å€¤ã«å¤‰æ›
                    neutral  = 1.0 - negative
                else:
                    positive = 0.0
                    negative = 0.0
                    neutral  = 1.0

                sentiment_scores = {
                    "positive": positive,
                    "negative": negative,
                    "neutral": neutral,
                    "compound": compound_score
                }
            
            results.append(sentiment_scores)
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
            progress = (idx + 1) / len(texts)
            progress_bar.progress(progress)
            
            analyzer_type = "ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰" if isinstance(analyzer, SimpleSentimentAnalyzer) else "osetiãƒ¢ãƒ¼ãƒ‰"
            status_text.text(f"{analyzer_type} ã§åˆ†æä¸­... {idx+1}/{len(texts)} ({progress*100:.1f}%)")
            
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒ‹ãƒ¥ãƒ¼ãƒˆãƒ©ãƒ«ã‚¹ã‚³ã‚¢
            st.warning(f"ãƒ†ã‚­ã‚¹ãƒˆ{idx+1}ã®åˆ†æã§ã‚¨ãƒ©ãƒ¼: {e}")
            results.append({
                "positive": 0.0,
                "negative": 0.0,
                "neutral": 1.0,
                "compound": 0.0
            })
            continue
    
    analyzer_type = "ç°¡æ˜“æ„Ÿæƒ…åˆ†æ" if isinstance(analyzer, SimpleSentimentAnalyzer) else "osetiæ„Ÿæƒ…åˆ†æ"
    status_text.text(f"âœ… {analyzer_type}å®Œäº†ï¼")
    progress_bar.progress(1.0)
    
    return results

# æ„Ÿæƒ…åˆ†æå®Ÿè¡Œ
analyzer_name = "ç°¡æ˜“æ„Ÿæƒ…åˆ†æ (MeCabä¸è¦)" if isinstance(analyzer, SimpleSentimentAnalyzer) else "osetiæ„Ÿæƒ…åˆ†æ"

if st.button(f"æ„Ÿæƒ…åˆ†æå®Ÿè¡Œ ({analyzer_name})", type="primary"):
    
    if isinstance(analyzer, SimpleSentimentAnalyzer):
        st.info("ç°¡æ˜“æ„Ÿæƒ…åˆ†æã«ã‚ˆã‚‹æ„Ÿæƒ…åˆ†æã‚’é–‹å§‹ã—ã¾ã™ï¼ˆMeCabä¸è¦ï¼‰")
    else:
        st.info("osetiãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã‚ˆã‚‹æ„Ÿæƒ…åˆ†æã‚’é–‹å§‹ã—ã¾ã™")
    
    # ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆæº–å‚™
    texts = sample_data[script_col].astype(str).tolist()
    
    # ãƒãƒƒãƒæ„Ÿæƒ…åˆ†æå®Ÿè¡Œ
    sentiment_results = analyze_sentiment_batch(texts, text_preprocessing)
    
    # çµæœã‚’DataFrameã«çµåˆ
    results_df = pd.DataFrame(sentiment_results)
    results_df["revenue"] = sample_data[revenue_col].values
    results_df["text_sample"] = [text[:100] + "..." for text in texts]
    
    # æ„Ÿæƒ…åˆ¤å®šï¼ˆãƒã‚¸ãƒ†ã‚£ãƒ–/ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼‰ã®è¿½åŠ 
    results_df["sentiment_label"] = results_df["compound"].apply(
        lambda x: "ãƒã‚¸ãƒ†ã‚£ãƒ–" if x > 0.1 else "ãƒã‚¬ãƒ†ã‚£ãƒ–" if x < -0.1 else "ä¸­æ€§"
    )
    
    st.success(f" {len(results_df)}ä»¶ã®æ„Ÿæƒ…åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    
    # å„å°æœ¬ãƒ‡ãƒ¼ã‚¿ã®æ„Ÿæƒ…åˆ¤å®šä¸€è¦§è¡¨ç¤º
    st.subheader(" å„å°æœ¬ãƒ‡ãƒ¼ã‚¿ã®æ„Ÿæƒ…åˆ¤å®šä¸€è¦§")
    
    # æ„Ÿæƒ…åˆ¤å®šçµæœã®ã‚µãƒãƒªãƒ¼
    sentiment_counts = results_df["sentiment_label"].value_counts()
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ãƒã‚¸ãƒ†ã‚£ãƒ–", f"{sentiment_counts.get('ãƒã‚¸ãƒ†ã‚£ãƒ–', 0)}ä»¶", 
                 f"{sentiment_counts.get('ãƒã‚¸ãƒ†ã‚£ãƒ–', 0) / len(results_df) * 100:.1f}%")
    with col2:
        st.metric("ãƒã‚¬ãƒ†ã‚£ãƒ–", f"{sentiment_counts.get('ãƒã‚¬ãƒ†ã‚£ãƒ–', 0)}ä»¶",
                 f"{sentiment_counts.get('ãƒã‚¬ãƒ†ã‚£ãƒ–', 0) / len(results_df) * 100:.1f}%")
    with col3:
        st.metric("ä¸­æ€§", f"{sentiment_counts.get('ä¸­æ€§', 0)}ä»¶",
                 f"{sentiment_counts.get('ä¸­æ€§', 0) / len(results_df) * 100:.1f}%")
    
    # å°æœ¬ãƒ‡ãƒ¼ã‚¿ã¨æ„Ÿæƒ…åˆ¤å®šçµæœã®ä¸€è¦§è¡¨
    display_df = pd.DataFrame({
        "ç•ªå·": range(1, len(results_df) + 1),
        "å°æœ¬ãƒ‡ãƒ¼ã‚¿ï¼ˆæŠœç²‹ï¼‰": results_df["text_sample"],
        "æ„Ÿæƒ…åˆ¤å®š": results_df["sentiment_label"],
        "ç·åˆã‚¹ã‚³ã‚¢": results_df["compound"].round(3),
        "ãƒã‚¸ãƒ†ã‚£ãƒ–": results_df["positive"].round(3),
        "ãƒã‚¬ãƒ†ã‚£ãƒ–": results_df["negative"].round(3),
        "åç›Š": results_df["revenue"]
    })
    
    # æ„Ÿæƒ…åˆ¥ã®è‰²åˆ†ã‘ã‚’é©ç”¨
    def highlight_sentiment(row):
        if row["æ„Ÿæƒ…åˆ¤å®š"] == "ãƒã‚¸ãƒ†ã‚£ãƒ–":
            return ['background-color: #e6ffe6'] * len(row)
        elif row["æ„Ÿæƒ…åˆ¤å®š"] == "ãƒã‚¬ãƒ†ã‚£ãƒ–":
            return ['background-color: #ffe6e6'] * len(row)
        else:
            return ['background-color: #f5f5f5'] * len(row)
    
    st.dataframe(
        display_df.style.apply(highlight_sentiment, axis=1),
        use_container_width=True,
        height=400
    )
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ©Ÿèƒ½
    st.subheader("æ„Ÿæƒ…åˆ¥ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°")
    
    filter_emotion = st.selectbox(
        "è¡¨ç¤ºã™ã‚‹æ„Ÿæƒ…ã‚’é¸æŠ:",
        options=["å…¨ã¦"] + list(sentiment_counts.index)
    )
    
    if filter_emotion != "å…¨ã¦":
        filtered_df = display_df[display_df["æ„Ÿæƒ…åˆ¤å®š"] == filter_emotion]
        st.write(f"**{filter_emotion}ã®å°æœ¬ãƒ‡ãƒ¼ã‚¿ ({len(filtered_df)}ä»¶):**")
        st.dataframe(
            filtered_df.style.apply(highlight_sentiment, axis=1),
            use_container_width=True,
            height=300
        )
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœã®çµ±è¨ˆ
        if len(filtered_df) > 0:
            avg_revenue = filtered_df["åç›Š"].mean()
            avg_score = filtered_df["ç·åˆã‚¹ã‚³ã‚¢"].mean()
            
            col1, col2 = st.columns(2)
            with col1:
                st.metric(f"{filter_emotion}ã®å¹³å‡åç›Š", f"{avg_revenue:.2f}")
            with col2:
                st.metric(f"{filter_emotion}ã®å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢", f"{avg_score:.3f}")
    
    # åŸºæœ¬çµ±è¨ˆè¡¨ç¤º
    st.subheader("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åŸºæœ¬çµ±è¨ˆ")
    
    emotion_stats = results_df[["positive", "negative", "neutral", "compound"]].describe()
    st.dataframe(emotion_stats.round(3))
    
    # ç›¸é–¢åˆ†æ
    st.subheader("æ„Ÿæƒ…-åç›Šç›¸é–¢åˆ†æ")
    
    emotion_cols = ["positive", "negative", "neutral", "compound"]
    correlation_results = []
    
    for emotion in emotion_cols:
        # ãƒ‡ãƒ¼ã‚¿ã®æœ‰åŠ¹æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        emotion_data = results_df[emotion].values
        revenue_data = results_df["revenue"].values
        
        # å®šæ•°é…åˆ—ã‚„NaNå€¤ã‚’ãƒã‚§ãƒƒã‚¯
        if (np.std(emotion_data) == 0 or np.std(revenue_data) == 0 or 
            np.isnan(emotion_data).all() or np.isnan(revenue_data).all()):
            # å®šæ•°é…åˆ—ã®å ´åˆã¯ç›¸é–¢ä¿‚æ•°ã‚’0ã¨ã™ã‚‹
            pearson_corr, pearson_p = 0.0, 1.0
            spearman_corr, spearman_p = 0.0, 1.0
        else:
            try:
                # ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢
                pearson_corr, pearson_p = pearsonr(emotion_data, revenue_data)
                # ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢  
                spearman_corr, spearman_p = spearmanr(emotion_data, revenue_data)
                
                # NaNå€¤ã®å‡¦ç†
                if np.isnan(pearson_corr):
                    pearson_corr, pearson_p = 0.0, 1.0
                if np.isnan(spearman_corr):
                    spearman_corr, spearman_p = 0.0, 1.0
                    
            except Exception as e:
                st.warning(f"ç›¸é–¢è¨ˆç®—ã‚¨ãƒ©ãƒ¼ ({emotion}): {str(e)}")
                pearson_corr, pearson_p = 0.0, 1.0
                spearman_corr, spearman_p = 0.0, 1.0
        
        emotion_names = {
            "positive": "ãƒã‚¸ãƒ†ã‚£ãƒ–",
            "negative": "ãƒã‚¬ãƒ†ã‚£ãƒ–", 
            "neutral": "ä¸­æ€§",
            "compound": "ç·åˆæ„Ÿæƒ…"
        }
        
        correlation_results.append({
            "æ„Ÿæƒ…": emotion_names[emotion],
            "ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢": pearson_corr,
            "ãƒ”ã‚¢ã‚½ãƒ³på€¤": pearson_p,
            "ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢": spearman_corr,
            "ã‚¹ãƒ”ã‚¢ãƒãƒ³på€¤": spearman_p,
            "çµ±è¨ˆçš„æœ‰æ„æ€§": "æœ‰æ„" if pearson_p < 0.05 else "éæœ‰æ„"
        })
    
    corr_df = pd.DataFrame(correlation_results).sort_values("ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢", key=abs, ascending=False)
    
    # ç›¸é–¢çµæœè¡¨ç¤º
    st.dataframe(
        corr_df.style.format({
            "ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢": "{:.3f}",
            "ãƒ”ã‚¢ã‚½ãƒ³på€¤": "{:.3f}",
            "ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢": "{:.3f}",
            "ã‚¹ãƒ”ã‚¢ãƒãƒ³på€¤": "{:.3f}"
        }),
        use_container_width=True
    )
    
    # å¯è¦–åŒ–
    st.subheader("ğŸ“Š ç›¸é–¢å¯è¦–åŒ–")
    
    # ç›¸é–¢ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢
    bars1 = ax1.barh(corr_df["æ„Ÿæƒ…"], corr_df["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"])
    ax1.set_xlabel("ç›¸é–¢ä¿‚æ•°")
    ax1.set_title("æ„Ÿæƒ…-åç›Š ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢")
    ax1.axvline(0, color="black", linestyle="-", alpha=0.5)
    
    # ãƒãƒ¼ã®è‰²ä»˜ã‘
    for bar, corr in zip(bars1, corr_df["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"]):
        bar.set_color("red" if corr > 0 else "blue")
        bar.set_alpha(0.7)
    
    # ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢
    bars2 = ax2.barh(corr_df["æ„Ÿæƒ…"], corr_df["ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢"])
    ax2.set_xlabel("ç›¸é–¢ä¿‚æ•°")
    ax2.set_title("æ„Ÿæƒ…-åç›Š ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢")
    ax2.axvline(0, color="black", linestyle="-", alpha=0.5)
    
    # ãƒãƒ¼ã®è‰²ä»˜ã‘
    for bar, corr in zip(bars2, corr_df["ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢"]):
        bar.set_color("red" if corr > 0 else "blue")
        bar.set_alpha(0.7)
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
    st.subheader("ğŸ“Š æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ")
    
    emotion_means = results_df[["positive", "negative", "neutral", "compound"]].mean()
    emotion_names_jp = ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­æ€§", "ç·åˆæ„Ÿæƒ…"]
    
    fig, ax = plt.subplots(figsize=(12, 6))
    bars = ax.bar(emotion_names_jp, emotion_means.values)
    ax.set_ylabel("å¹³å‡ã‚¹ã‚³ã‚¢")
    ax.set_title("æ„Ÿæƒ…åˆ¥å¹³å‡ã‚¹ã‚³ã‚¢")
    ax.set_ylim(0, 1)
    
    # ãƒãƒ¼ã®è‰²ã‚’ç›¸é–¢ã®å¼·ã•ã§è‰²åˆ†ã‘
    colors = ['red' if corr_df.iloc[i]["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"] > 0 else 'blue' 
              for i in range(len(emotion_means))]
    for bar, color in zip(bars, colors):
        bar.set_color(color)
        bar.set_alpha(0.7)
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # æœ€é«˜ç›¸é–¢æ„Ÿæƒ…ã®æ•£å¸ƒå›³
    if len(corr_df) > 0:
        best_emotion_jp = corr_df.iloc[0]["æ„Ÿæƒ…"]
        
        # æ„Ÿæƒ…åã‹ã‚‰è‹±èªã‚«ãƒ©ãƒ åã¸ã®ãƒãƒƒãƒ”ãƒ³ã‚°
        emotion_name_mapping = {
            "ãƒã‚¸ãƒ†ã‚£ãƒ–": "positive",
            "ãƒã‚¬ãƒ†ã‚£ãƒ–": "negative", 
            "ä¸­æ€§": "neutral",
            "ç·åˆæ„Ÿæƒ…": "compound"
        }
        best_emotion_col = emotion_name_mapping[best_emotion_jp]
        best_corr = corr_df.iloc[0]["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"]
        
        st.subheader(f"ğŸ¯ æœ€é«˜ç›¸é–¢æ„Ÿæƒ…: {best_emotion_jp} (r={best_corr:.3f})")
        
        fig, ax = plt.subplots(figsize=(10, 6))
        scatter = ax.scatter(results_df[best_emotion_col], results_df["revenue"], 
                           alpha=0.6, c=results_df[best_emotion_col], cmap="viridis")
        ax.set_xlabel(f"{best_emotion_jp}ã‚¹ã‚³ã‚¢")
        ax.set_ylabel("åç›Š")
        ax.set_title(f"{best_emotion_jp}ã‚¹ã‚³ã‚¢ vs åç›Š")
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
        try:
            x_data = results_df[best_emotion_col].values
            y_data = results_df["revenue"].values
            
            # ãƒ‡ãƒ¼ã‚¿ã®æœ‰åŠ¹æ€§ã‚’ãƒã‚§ãƒƒã‚¯
            if (np.std(x_data) > 1e-10 and np.std(y_data) > 1e-10 and 
                not np.isnan(x_data).any() and not np.isnan(y_data).any() and 
                len(x_data) > 1):
                
                z = np.polyfit(x_data, y_data, 1)
                p = np.poly1d(z)
                ax.plot(x_data, p(x_data), "r--", alpha=0.8, linewidth=2)
            else:
                st.info(f"ğŸ“ {best_emotion_jp}ãƒ‡ãƒ¼ã‚¿ã«ä¸€å®šå€¤ãŒå¤šã„ãŸã‚ã€ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚’çœç•¥ã—ã¾ã™ã€‚")
                
        except Exception as e:
            st.warning(f"ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³æç”»ã‚¨ãƒ©ãƒ¼: {str(e)}")
            st.info("ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ã«æ•°å€¤çš„ãªå•é¡ŒãŒã‚ã‚‹ãŸã‚ã€ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãªã—ã§è¡¨ç¤ºã—ã¾ã™ã€‚")
        
        plt.colorbar(scatter, label=f"{best_emotion_jp}ã‚¹ã‚³ã‚¢")
        plt.tight_layout()
        st.pyplot(fig)
    
    # æ„Ÿæƒ…åˆ†å¸ƒã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    st.subheader("ğŸŒ¡ï¸ æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹")
    
    emotion_corr = results_df[["positive", "negative", "neutral", "compound", "revenue"]].corr()
    emotion_corr.columns = ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­æ€§", "ç·åˆæ„Ÿæƒ…", "åç›Š"]
    emotion_corr.index = ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­æ€§", "ç·åˆæ„Ÿæƒ…", "åç›Š"]
    
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(emotion_corr, annot=True, cmap="coolwarm", center=0, 
                square=True, fmt=".3f", ax=ax)
    ax.set_title("æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹")
    plt.tight_layout()
    st.pyplot(fig)
    
    # çµæœè¦ç´„
    st.subheader("ğŸ“‹ åˆ†æçµæœè¦ç´„")
    
    significant_emotions = corr_df[corr_df["çµ±è¨ˆçš„æœ‰æ„æ€§"] == "æœ‰æ„"]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("åˆ†æä»¶æ•°", f"{len(results_df):,}ä»¶")
        st.metric("æœ‰æ„ãªç›¸é–¢æ•°", f"{len(significant_emotions)}å€‹")
        
    with col2:
        strongest_corr = corr_df.iloc[0]
        st.metric("æœ€å¼·ç›¸é–¢", f"{strongest_corr['æ„Ÿæƒ…']}")
        st.metric("ç›¸é–¢ä¿‚æ•°", f"{strongest_corr['ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢']:.3f}")
    
    if len(significant_emotions) > 0:
        st.success(f"âœ… {len(significant_emotions)}å€‹ã®æ„Ÿæƒ…ã§çµ±è¨ˆçš„ã«æœ‰æ„ãªç›¸é–¢ã‚’ç™ºè¦‹")
        
        for _, row in significant_emotions.iterrows():
            correlation_strength = "å¼·ã„" if abs(row["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"]) > 0.5 else "ä¸­ç¨‹åº¦" if abs(row["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"]) > 0.3 else "å¼±ã„"
            correlation_direction = "æ­£ã®" if row["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"] > 0 else "è² ã®"
            
            st.write(f"â€¢ **{row['æ„Ÿæƒ…']}**: {correlation_direction}{correlation_strength}ç›¸é–¢ (r={row['ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢']:.3f}, p={row['ãƒ”ã‚¢ã‚½ãƒ³på€¤']:.3f})")
    else:
        st.warning("âš ï¸ çµ±è¨ˆçš„ã«æœ‰æ„ãªç›¸é–¢ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
    
    # æ„Ÿæƒ…åˆ¥åç›Šåˆ†æ
    st.subheader("ğŸ’° æ„Ÿæƒ…åˆ¥åç›Šåˆ†æ")
    
    # ç·åˆæ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã§ä¸Šä½ãƒ»ä¸‹ä½ã‚’åˆ†é¡
    compound_median = results_df["compound"].median()
    
    high_sentiment = results_df[results_df["compound"] >= compound_median]
    low_sentiment = results_df[results_df["compound"] < compound_median]
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric(
            "é«˜æ„Ÿæƒ…ã‚°ãƒ«ãƒ¼ãƒ—å¹³å‡åç›Š", 
            f"{high_sentiment['revenue'].mean():.2f}",
            f"{high_sentiment['revenue'].mean() - results_df['revenue'].mean():.2f}"
        )
        st.write(f"ä»¶æ•°: {len(high_sentiment)}ä»¶")
        
    with col2:
        st.metric(
            "ä½æ„Ÿæƒ…ã‚°ãƒ«ãƒ¼ãƒ—å¹³å‡åç›Š",
            f"{low_sentiment['revenue'].mean():.2f}",
            f"{low_sentiment['revenue'].mean() - results_df['revenue'].mean():.2f}"
        )
        st.write(f"ä»¶æ•°: {len(low_sentiment)}ä»¶")
    
    # åç›Šåˆ†å¸ƒæ¯”è¼ƒ
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.hist([high_sentiment["revenue"], low_sentiment["revenue"]], 
            bins=20, alpha=0.7, label=["é«˜æ„Ÿæƒ…", "ä½æ„Ÿæƒ…"], color=["red", "blue"])
    ax.set_xlabel("åç›Š")
    ax.set_ylabel("é »åº¦")
    ax.set_title("æ„Ÿæƒ…ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥åç›Šåˆ†å¸ƒ")
    ax.legend()
    plt.tight_layout()
    st.pyplot(fig)
    
    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.subheader("ğŸ’¾ çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    
    # è©³ç´°çµæœCSVï¼ˆæ„Ÿæƒ…åˆ¤å®šãƒ©ãƒ™ãƒ«ã‚’å«ã‚€ï¼‰
    download_df = results_df.copy()
    download_df = download_df[["text_sample", "sentiment_label", "compound", "positive", "negative", "neutral", "revenue"]]
    download_df.columns = ["å°æœ¬ãƒ‡ãƒ¼ã‚¿ï¼ˆæŠœç²‹ï¼‰", "æ„Ÿæƒ…åˆ¤å®š", "ç·åˆã‚¹ã‚³ã‚¢", "ãƒã‚¸ãƒ†ã‚£ãƒ–ã‚¹ã‚³ã‚¢", "ãƒã‚¬ãƒ†ã‚£ãƒ–ã‚¹ã‚³ã‚¢", "ä¸­æ€§ã‚¹ã‚³ã‚¢", "åç›Š"]
    
    detailed_csv = download_df.to_csv(index=False, encoding="utf-8-sig")
    st.download_button(
        label="ğŸ“ è©³ç´°åˆ†æçµæœã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=detailed_csv,
        file_name="sentiment_analysis_detailed_with_labels.csv",
        mime="text/csv"
    )
    
    # æ„Ÿæƒ…åˆ¤å®šä¸€è¦§CSV
    sentiment_list_csv = display_df.to_csv(index=False, encoding="utf-8-sig")
    st.download_button(
        label="ğŸ“‹ æ„Ÿæƒ…åˆ¤å®šä¸€è¦§ã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=sentiment_list_csv,
        file_name="sentiment_judgment_list.csv",
        mime="text/csv"
    )
    
    # ç›¸é–¢çµæœCSV
    correlation_csv = corr_df.to_csv(index=False, encoding="utf-8-sig")
    st.download_button(
        label="ğŸ“Š ç›¸é–¢åˆ†æçµæœã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", 
        data=correlation_csv,
        file_name="sentiment_correlation_free.csv",
        mime="text/csv"
    )

# ä½¿ç”¨æ–¹æ³•èª¬æ˜
with st.expander("â„¹ï¸ ä½¿ç”¨æ–¹æ³•ã¨ãƒ’ãƒ³ãƒˆ"):
    st.markdown("""
    ### ğŸ¯ æ©Ÿèƒ½æ¦‚è¦
    - **æ„Ÿæƒ…åˆ†æ**: æ—¥æœ¬èªæ„Ÿæƒ…åˆ†æï¼ˆosetiã¾ãŸã¯ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ï¼‰
    - **ç›¸é–¢åˆ†æ**: æ„Ÿæƒ…ã‚¹ã‚³ã‚¢ã¨åç›Šã®ç›¸é–¢é–¢ä¿‚ã‚’çµ±è¨ˆçš„ã«æ¤œè¨¼
    - **å¯è¦–åŒ–**: ç›¸é–¢é–¢ä¿‚ã€æ„Ÿæƒ…åˆ†å¸ƒã€ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤º
    - **ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ**: åˆ†æçµæœã‚’CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½
    
    ### ğŸ”§ æ„Ÿæƒ…åˆ†æãƒ¢ãƒ¼ãƒ‰
    **osetiãƒ¢ãƒ¼ãƒ‰ï¼ˆæ¨å¥¨ï¼‰:**
    - MeCabã«ã‚ˆã‚‹é«˜ç²¾åº¦ãªå½¢æ…‹ç´ è§£æ
    - æ—¥æœ¬èªå°‚ç”¨ã®æ„Ÿæƒ…åˆ†æãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    - ã‚ˆã‚Šè©³ç´°ã§ç²¾å¯†ãªæ„Ÿæƒ…åˆ†æ
    
    **ç°¡æ˜“ãƒ¢ãƒ¼ãƒ‰ï¼ˆMeCabä¸è¦ï¼‰:**
    - ã‚·ã‚¹ãƒ†ãƒ è¨­å®šä¸è¦ã§å³åº§ã«åˆ©ç”¨å¯èƒ½
    - åŸºæœ¬çš„ãªæ„Ÿæƒ…èªå½™è¾æ›¸ã«ã‚ˆã‚‹åˆ†æ
    - MeCabè¨­å®šå•é¡Œã®å›é¿ç­–ã¨ã—ã¦æä¾›
    
    ### âš™ï¸ è¨­å®šã®ãƒ’ãƒ³ãƒˆ
    - **åŸºæœ¬å‰å‡¦ç†**: è»½å¾®ãªã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®ã¿
    - **è©³ç´°å‰å‡¦ç†**: URLã€è¨˜å·ã€æ•°å­—ã‚’é™¤å»ã—ã¦ã‚ˆã‚Šç²¾å¯†ã«åˆ†æ
    - **æœ€å¤§åˆ†æä»¶æ•°**: å‡¦ç†é€Ÿåº¦ã‚’è€ƒæ…®ã—ã¦èª¿æ•´
    
    ### ğŸ“Š çµæœã®è§£é‡ˆ
    - **positive**: ãƒã‚¸ãƒ†ã‚£ãƒ–æ„Ÿæƒ…ã®å¼·ã•ï¼ˆ0-1ï¼‰
    - **negative**: ãƒã‚¬ãƒ†ã‚£ãƒ–æ„Ÿæƒ…ã®å¼·ã•ï¼ˆ0-1ï¼‰
    - **neutral**: ä¸­æ€§çš„æ„Ÿæƒ…ã®å¼·ã•ï¼ˆ0-1ï¼‰
    - **compound**: ç·åˆæ„Ÿæƒ…ã‚¹ã‚³ã‚¢ï¼ˆ-1ã‹ã‚‰1ï¼‰
    - **çµ±è¨ˆçš„æœ‰æ„æ€§**: på€¤ < 0.05 ã§ç›¸é–¢ãŒçµ±è¨ˆçš„ã«æ„å‘³ã‚ã‚Š
    
    ### ğŸ†š å„ç‰ˆã®ç‰¹å¾´æ¯”è¼ƒ
    - **LLMç‰ˆ**: AI ã«ã‚ˆã‚‹è¤‡é›‘ãªæ„Ÿæƒ…åˆ†æã€APIæ–™é‡‘ãŒç™ºç”Ÿ
    - **osetiç‰ˆ**: é«˜ç²¾åº¦ã€MeCabè¦ã€å®Œå…¨ç„¡æ–™
    - **ç°¡æ˜“ç‰ˆ**: åŸºæœ¬ç²¾åº¦ã€è¨­å®šä¸è¦ã€å®Œå…¨ç„¡æ–™
    """)

st.markdown("---")
if isinstance(analyzer, SimpleSentimentAnalyzer):
    st.caption("ğŸš€ ç°¡æ˜“æ„Ÿæƒ…åˆ†æ (MeCabä¸è¦) | ğŸ“Š å°æœ¬ãƒ‡ãƒ¼ã‚¿åˆ†æãƒãƒ–")
else:
    st.caption("ğŸ’– oseti ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã‚ˆã‚‹æ„Ÿæƒ…åˆ†æ | ğŸ“Š å°æœ¬ãƒ‡ãƒ¼ã‚¿åˆ†æãƒãƒ–")