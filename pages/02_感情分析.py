import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr, spearmanr
import os
import anthropic
from typing import List, Dict
import time

st.set_page_config(page_title="â‘¡ æ„Ÿæƒ…åˆ†æ", page_icon="ğŸ˜Š", layout="wide")
st.title("ğŸ˜Š æ„Ÿæƒ…åˆ†æï¼ˆåç›Šã¨ã®ç›¸é–¢åˆ†æï¼‰")

if "df" not in st.session_state:
    st.warning("ã¾ãšãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã§Excelã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

df = st.session_state["df"].copy()
meta = st.session_state.get("meta", {})

# Anthropic API ã‚­ãƒ¼ã®ç¢ºèª
if 'ANTHROPIC_API_KEY' not in os.environ:
    st.error("Anthropic API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•° 'ANTHROPIC_API_KEY' ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# åˆ—é¸æŠ
st.subheader("ğŸ“Š ãƒ‡ãƒ¼ã‚¿é¸æŠ")
text_col = st.selectbox(
    "å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆåˆ—", 
    options=list(df.columns), 
    index=list(df.columns).index(meta.get("text_col")) if meta.get("text_col") in df.columns else 0
)
profit_col = st.selectbox(
    "åç›Šåˆ—", 
    options=[c for c in df.columns if c != text_col], 
    index=[i for i, c in enumerate(df.columns) if c != text_col and c == meta.get("profit_col")][0] if meta.get("profit_col") in df.columns else 0
)

# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
df["_text"] = df[text_col].fillna("").astype(str)
df["_profit"] = pd.to_numeric(df[profit_col], errors="coerce")

# æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
valid_data = df[(df["_text"].str.len() > 10) & df["_profit"].notna()].copy()
if len(valid_data) < 3:
    st.error("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆãŒ10æ–‡å­—ä»¥ä¸Šã§ã€åç›Šãƒ‡ãƒ¼ã‚¿ãŒæ•°å€¤ã§ã‚ã‚‹è¡ŒãŒ3è¡Œä»¥ä¸Šå¿…è¦ã§ã™ã€‚")
    st.stop()

st.success(f"âœ… åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {len(valid_data)}ä»¶")

# ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°è¨­å®š
st.subheader("âš™ï¸ åˆ†æè¨­å®š")
col1, col2 = st.columns(2)

with col1:
    max_samples = st.slider(
        "åˆ†æã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆAPIä½¿ç”¨é‡èª¿æ•´ï¼‰",
        min_value=3,
        max_value=min(100, len(valid_data)),
        value=min(20, len(valid_data)),
        help="å¤šã„ã»ã©æ­£ç¢ºã ãŒã€APIä½¿ç”¨é‡ã¨ã‚³ã‚¹ãƒˆãŒå¢—åŠ ã—ã¾ã™"
    )

with col2:
    sentiment_model = st.selectbox(
        "æ„Ÿæƒ…åˆ†æã®è©³ç´°åº¦",
        options=["åŸºæœ¬æ„Ÿæƒ…ï¼ˆ5åˆ†é¡ï¼‰", "è©³ç´°æ„Ÿæƒ…ï¼ˆ10åˆ†é¡ï¼‰"],
        index=0,
        help="è©³ç´°ã«ã™ã‚‹ã»ã©APIä½¿ç”¨é‡ãŒå¢—åŠ ã—ã¾ã™"
    )

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
if len(valid_data) > max_samples:
    # åç›Šã®åˆ†å¸ƒã‚’è€ƒæ…®ã—ãŸã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    sample_data = valid_data.sample(n=max_samples, random_state=42)
else:
    sample_data = valid_data.copy()

# æ„Ÿæƒ…åˆ†æã®å®Ÿè¡Œ
def analyze_sentiment_batch(texts: List[str], model_type: str) -> List[Dict]:
    """ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œ"""
    client = anthropic.Anthropic(api_key=os.environ['ANTHROPIC_API_KEY'])
    
    if model_type == "åŸºæœ¬æ„Ÿæƒ…ï¼ˆ5åˆ†é¡ï¼‰":
        emotions = ["ãƒã‚¸ãƒ†ã‚£ãƒ–", "ãƒã‚¬ãƒ†ã‚£ãƒ–", "ä¸­æ€§", "èˆˆå¥®", "ä¸å®‰"]
        prompt_template = """ä»¥ä¸‹ã®å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ: "{text}"

ä»¥ä¸‹ã®5ã¤ã®æ„Ÿæƒ…ã‚«ãƒ†ã‚´ãƒªãƒ¼ãã‚Œãã‚Œã«ã¤ã„ã¦ã€0-10ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„:
- ãƒã‚¸ãƒ†ã‚£ãƒ–ï¼ˆå–œã³ã€å¸Œæœ›ã€æº€è¶³ãªã©ï¼‰
- ãƒã‚¬ãƒ†ã‚£ãƒ–ï¼ˆæ‚²ã—ã¿ã€æ€’ã‚Šã€ä¸æº€ãªã©ï¼‰  
- ä¸­æ€§ï¼ˆè½ã¡ç€ãã€å¹³å¸¸ã€å®¢è¦³çš„ãªã©ï¼‰
- èˆˆå¥®ï¼ˆé©šãã€é«˜æšã€ç†±ç‹‚ãªã©ï¼‰
- ä¸å®‰ï¼ˆå¿ƒé…ã€ææ€–ã€ç·Šå¼µãªã©ï¼‰

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{"ãƒã‚¸ãƒ†ã‚£ãƒ–": ã‚¹ã‚³ã‚¢, "ãƒã‚¬ãƒ†ã‚£ãƒ–": ã‚¹ã‚³ã‚¢, "ä¸­æ€§": ã‚¹ã‚³ã‚¢, "èˆˆå¥®": ã‚¹ã‚³ã‚¢, "ä¸å®‰": ã‚¹ã‚³ã‚¢}}"""
    else:
        emotions = ["å–œã³", "æ‚²ã—ã¿", "æ€’ã‚Š", "ææ€–", "é©šã", "å«Œæ‚ª", "æœŸå¾…", "ä¿¡é ¼", "ä¸­æ€§", "æ··åˆ"]
        prompt_template = """ä»¥ä¸‹ã®å°æœ¬ãƒ†ã‚­ã‚¹ãƒˆã®æ„Ÿæƒ…ã‚’è©³ç´°åˆ†æã—ã¦ãã ã•ã„ã€‚

ãƒ†ã‚­ã‚¹ãƒˆ: "{text}"

ä»¥ä¸‹ã®10ã®æ„Ÿæƒ…ã‚«ãƒ†ã‚´ãƒªãƒ¼ãã‚Œãã‚Œã«ã¤ã„ã¦ã€0-10ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡ã—ã¦ãã ã•ã„:
- å–œã³ã€æ‚²ã—ã¿ã€æ€’ã‚Šã€ææ€–ã€é©šãã€å«Œæ‚ªã€æœŸå¾…ã€ä¿¡é ¼ã€ä¸­æ€§ã€æ··åˆ

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{"å–œã³": ã‚¹ã‚³ã‚¢, "æ‚²ã—ã¿": ã‚¹ã‚³ã‚¢, "æ€’ã‚Š": ã‚¹ã‚³ã‚¢, "ææ€–": ã‚¹ã‚³ã‚¢, "é©šã": ã‚¹ã‚³ã‚¢, "å«Œæ‚ª": ã‚¹ã‚³ã‚¢, "æœŸå¾…": ã‚¹ã‚³ã‚¢, "ä¿¡é ¼": ã‚¹ã‚³ã‚¢, "ä¸­æ€§": ã‚¹ã‚³ã‚¢, "æ··åˆ": ã‚¹ã‚³ã‚¢}}"""
    
    results = []
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for i, text in enumerate(texts):
        try:
            status_text.text(f"æ„Ÿæƒ…åˆ†æä¸­... ({i+1}/{len(texts)})")
            
            # ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹å ´åˆã¯å…ˆé ­éƒ¨åˆ†ã‚’ä½¿ç”¨
            text_to_analyze = text[:1000] if len(text) > 1000 else text
            
            response = client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=200,
                messages=[{
                    "role": "user",
                    "content": prompt_template.format(text=text_to_analyze)
                }]
            )
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‘ãƒ¼ã‚¹
            response_text = response.content[0].text
            # JSONã®æŠ½å‡ºã‚’è©¦è¡Œ
            import json
            try:
                # JSONãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¢ã™
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                if json_start >= 0 and json_end > json_start:
                    json_str = response_text[json_start:json_end]
                    sentiment_scores = json.loads(json_str)
                else:
                    raise ValueError("JSON not found")
            except:
                # ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                sentiment_scores = {emotion: 5.0 for emotion in emotions}
                st.warning(f"ãƒ†ã‚­ã‚¹ãƒˆ {i+1} ã®æ„Ÿæƒ…åˆ†æçµæœã‚’ãƒ‘ãƒ¼ã‚¹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            
            results.append(sentiment_scores)
            progress_bar.progress((i + 1) / len(texts))
            
            # APIåˆ¶é™ã‚’è€ƒæ…®ã—ãŸçŸ­ã„å¾…æ©Ÿ
            time.sleep(0.5)
            
        except Exception as e:
            st.error(f"æ„Ÿæƒ…åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (ãƒ†ã‚­ã‚¹ãƒˆ {i+1}): {str(e)}")
            # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            sentiment_scores = {emotion: 5.0 for emotion in emotions}
            results.append(sentiment_scores)
    
    status_text.text("æ„Ÿæƒ…åˆ†æå®Œäº†!")
    progress_bar.progress(1.0)
    return results

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸš€ æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œ", type="primary"):
    with st.spinner("æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œä¸­..."):
        # ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆã®æº–å‚™
        texts_to_analyze = sample_data["_text"].tolist()
        
        # æ„Ÿæƒ…åˆ†æã®å®Ÿè¡Œ
        sentiment_results = analyze_sentiment_batch(texts_to_analyze, sentiment_model)
        
        # çµæœã‚’DataFrameã«çµ±åˆ
        sentiment_df = pd.DataFrame(sentiment_results)
        analysis_df = pd.concat([
            sample_data.reset_index(drop=True),
            sentiment_df
        ], axis=1)
        
        # çµæœã®ä¿å­˜
        st.session_state["sentiment_analysis_results"] = analysis_df
        st.session_state["sentiment_emotions"] = list(sentiment_df.columns)
        
        st.success("âœ… æ„Ÿæƒ…åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")

# çµæœã®è¡¨ç¤º
if "sentiment_analysis_results" in st.session_state:
    analysis_df = st.session_state["sentiment_analysis_results"]
    emotions = st.session_state["sentiment_emotions"]
    
    st.subheader("ğŸ“ˆ åˆ†æçµæœ")
    
    # åŸºæœ¬çµ±è¨ˆ
    st.markdown("#### æ„Ÿæƒ…ã‚¹ã‚³ã‚¢çµ±è¨ˆ")
    emotion_stats = analysis_df[emotions].describe().round(2)
    st.dataframe(emotion_stats)
    
    # ç›¸é–¢åˆ†æ
    st.markdown("#### æ„Ÿæƒ…ã¨åç›Šã®ç›¸é–¢åˆ†æ")
    
    correlations = []
    for emotion in emotions:
        try:
            pearson_r, pearson_p = pearsonr(analysis_df[emotion], analysis_df["_profit"])
            spearman_r, spearman_p = spearmanr(analysis_df[emotion], analysis_df["_profit"])
            
            correlations.append({
                "æ„Ÿæƒ…": emotion,
                "ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢": round(pearson_r, 3),
                "ãƒ”ã‚¢ã‚½ãƒ³på€¤": round(pearson_p, 4),
                "ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢": round(spearman_r, 3),
                "ã‚¹ãƒ”ã‚¢ãƒãƒ³på€¤": round(spearman_p, 4),
                "æœ‰æ„æ€§": "æœ‰æ„" if pearson_p < 0.05 else "éæœ‰æ„"
            })
        except:
            correlations.append({
                "æ„Ÿæƒ…": emotion,
                "ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢": 0,
                "ãƒ”ã‚¢ã‚½ãƒ³på€¤": 1,
                "ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢": 0,
                "ã‚¹ãƒ”ã‚¢ãƒãƒ³på€¤": 1,
                "æœ‰æ„æ€§": "è¨ˆç®—ã‚¨ãƒ©ãƒ¼"
            })
    
    corr_df = pd.DataFrame(correlations)
    st.dataframe(corr_df)
    
    # å¯è¦–åŒ–
    st.markdown("#### ğŸ“Š å¯è¦–åŒ–")
    
    # ç›¸é–¢ä¿‚æ•°ã®ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    plt.rcParams['font.family'] = ['DejaVu Sans']
    
    # 1. ç›¸é–¢ä¿‚æ•°ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
    axes[0, 0].barh(corr_df["æ„Ÿæƒ…"], corr_df["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"])
    axes[0, 0].set_title("æ„Ÿæƒ…ã¨åç›Šã®ç›¸é–¢ä¿‚æ•°")
    axes[0, 0].set_xlabel("ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢ä¿‚æ•°")
    axes[0, 0].axvline(x=0, color='black', linestyle='-', alpha=0.3)
    
    # 2. æ„Ÿæƒ…ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
    emotion_means = analysis_df[emotions].mean()
    axes[0, 1].bar(range(len(emotion_means)), emotion_means.values)
    axes[0, 1].set_title("å¹³å‡æ„Ÿæƒ…ã‚¹ã‚³ã‚¢")
    axes[0, 1].set_xticks(range(len(emotions)))
    axes[0, 1].set_xticklabels(emotions, rotation=45, ha='right')
    axes[0, 1].set_ylabel("å¹³å‡ã‚¹ã‚³ã‚¢")
    
    # 3. æ•£å¸ƒå›³ï¼ˆæœ€ã‚‚ç›¸é–¢ã®é«˜ã„æ„Ÿæƒ…ï¼‰
    best_emotion = corr_df.loc[corr_df["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"].abs().idxmax(), "æ„Ÿæƒ…"]
    axes[1, 0].scatter(analysis_df[best_emotion], analysis_df["_profit"], alpha=0.6)
    axes[1, 0].set_xlabel(f"{best_emotion} ã‚¹ã‚³ã‚¢")
    axes[1, 0].set_ylabel("åç›Š")
    axes[1, 0].set_title(f"{best_emotion}ã¨åç›Šã®æ•£å¸ƒå›³")
    
    # 4. åç›Šåˆ†å¸ƒ
    axes[1, 1].hist(analysis_df["_profit"], bins=10, alpha=0.7)
    axes[1, 1].set_title("åç›Šåˆ†å¸ƒ")
    axes[1, 1].set_xlabel("åç›Š")
    axes[1, 1].set_ylabel("é »åº¦")
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # ãƒ‡ãƒ¼ã‚¿è©³ç´°è¡¨ç¤º
    with st.expander("ğŸ“‹ è©³ç´°ãƒ‡ãƒ¼ã‚¿", expanded=False):
        display_cols = [text_col, profit_col] + emotions
        st.dataframe(analysis_df[display_cols])
    
    # çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    csv_data = analysis_df.to_csv(index=False).encode('utf-8-sig')
    st.download_button(
        label="ğŸ“¥ åˆ†æçµæœã‚’CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv_data,
        file_name="sentiment_analysis_results.csv",
        mime="text/csv"
    )
    
    # ä¸»è¦ãªç™ºè¦‹ã®è¦ç´„
    st.markdown("#### ğŸ” ä¸»è¦ãªç™ºè¦‹")
    
    # æœ€ã‚‚ç›¸é–¢ã®é«˜ã„æ„Ÿæƒ…
    max_corr_idx = corr_df["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"].abs().idxmax()
    max_corr_emotion = corr_df.iloc[max_corr_idx]
    
    if abs(max_corr_emotion["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"]) > 0.3:
        correlation_strength = "å¼·ã„"
    elif abs(max_corr_emotion["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"]) > 0.1:
        correlation_strength = "ä¸­ç¨‹åº¦"
    else:
        correlation_strength = "å¼±ã„"
    
    correlation_direction = "æ­£ã®" if max_corr_emotion["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"] > 0 else "è² ã®"
    
    st.write(f"""
    - **æœ€ã‚‚åç›Šã¨é–¢é€£ã®é«˜ã„æ„Ÿæƒ…**: {max_corr_emotion["æ„Ÿæƒ…"]} (ç›¸é–¢ä¿‚æ•°: {max_corr_emotion["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"]})
    - **ç›¸é–¢ã®å¼·ã•**: {correlation_strength}{correlation_direction}ç›¸é–¢
    - **çµ±è¨ˆçš„æœ‰æ„æ€§**: {max_corr_emotion["æœ‰æ„æ€§"]}
    - **åˆ†æã‚µãƒ³ãƒ—ãƒ«æ•°**: {len(analysis_df)}ä»¶
    """)
    
    if max_corr_emotion["æœ‰æ„æ€§"] == "æœ‰æ„":
        direction_text = "é«˜ããªã‚‹" if max_corr_emotion["ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢"] > 0 else "ä½ããªã‚‹"
        st.info(f"ğŸ’¡ **ç¤ºå”†**: å°æœ¬ã®ã€Œ{max_corr_emotion['æ„Ÿæƒ…']}ã€ã‚¹ã‚³ã‚¢ãŒé«˜ã„ã»ã©ã€åç›ŠãŒ{direction_text}å‚¾å‘ãŒã‚ã‚Šã¾ã™ã€‚")
    else:
        st.warning("âš ï¸ **æ³¨æ„**: çµ±è¨ˆçš„ã«æœ‰æ„ãªç›¸é–¢ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¢—ã‚„ã™ã‹ã€ä»–ã®è¦å› ã‚’æ¤œè¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")

else:
    st.info("ğŸ‘† ä¸Šè¨˜ã®è¨­å®šã‚’å®Œäº†å¾Œã€ã€Œæ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")